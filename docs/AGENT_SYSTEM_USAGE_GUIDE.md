# æ™ºèƒ½ä½“ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
3. [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
4. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
5. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
6. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### åŸºæœ¬é…ç½®
```python
# config.py
AGENT_CONFIG = {
    "model": "gpt-4",
    "temperature": 0.7,
    "max_tokens": 3000,
    "fastgpt_url": "http://localhost:3001",
    "cache_enabled": True,
    "cache_ttl": 3600,
    "max_retries": 3,
    "max_concurrent": 5
}
```

### å¯åŠ¨åä½œå·¥ä½œæµ
```python
from python-backend.agents.agent_manager import AgentWorkflowManager

# åˆ›å»ºç®¡ç†å™¨
manager = AgentWorkflowManager()

# å¯åŠ¨å·¥ä½œæµ
workflow_id = await manager.start_collaborative_workflow(
    tenant_id="your_tenant_id",
    tender_document="æ‹›æ ‡æ–‡æ¡£å†…å®¹...",
    config=AGENT_CONFIG,
    max_iterations=3
)

# è·å–çŠ¶æ€
status = manager.get_collaborative_workflow_status(workflow_id)
print(f"å·¥ä½œæµçŠ¶æ€: {status['status']}")
print(f"å½“å‰é˜¶æ®µ: {status['current_step']}")
print(f"è¿›åº¦: {status['progress']}%")
```

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. åä½œå·¥ä½œæµ

#### ä¸‰é˜¶æ®µæµç¨‹
```python
from python-backend.agents.collaborative_workflow import CollaborativeWorkflow

workflow = CollaborativeWorkflow(tenant_id, config)

# æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
result = await workflow.execute_collaborative_workflow(
    tender_document="æ‹›æ ‡æ–‡æ¡£...",
    max_iterations=3
)

# ç»“æœåŒ…å«
# - analysis: åˆ†æç»“æœ
# - content: ç”Ÿæˆçš„å†…å®¹
# - verification: éªŒè¯ç»“æœ
# - collaboration_history: åä½œå†å²
```

#### é˜¶æ®µè¯´æ˜
- **é˜¶æ®µ1ï¼šåˆ†æå’ŒçŸ¥è¯†æ£€ç´¢**
  - å¹¶è¡Œæ‰§è¡Œæ‹›æ ‡åˆ†æå’ŒçŸ¥è¯†æ£€ç´¢
  - æå–éœ€æ±‚ã€è¯„ä¼°é£é™©
  - æ£€ç´¢ç›¸å…³çŸ¥è¯†å’Œæ¡ˆä¾‹

- **é˜¶æ®µ2ï¼šåä½œå†…å®¹ç”Ÿæˆ**
  - ç”ŸæˆæŠ€æœ¯ã€å•†åŠ¡ã€å®æ–½æ–¹æ¡ˆ
  - å¤šè½®ä¼˜åŒ–å¾ªç¯ï¼ˆæœ€å¤š3è½®ï¼‰
  - è´¨é‡æ£€æŸ¥å’Œè‡ªåŠ¨æ”¹è¿›

- **é˜¶æ®µ3ï¼šæœ€ç»ˆéªŒè¯**
  - å…¨é¢åˆè§„éªŒè¯
  - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
  - ç¡®å®šå®¡æ‰¹çŠ¶æ€

### 2. é”™è¯¯å¤„ç†å’Œé‡è¯•

#### ä½¿ç”¨é‡è¯•è£…é¥°å™¨
```python
from python-backend.agents.error_handling import with_retry, RetryConfig

# è‡ªå®šä¹‰é‡è¯•é…ç½®
retry_config = RetryConfig(
    max_retries=3,
    initial_delay=1.0,
    max_delay=60.0,
    exponential_base=2.0,
    jitter=True
)

@with_retry(retry_config=retry_config)
async def process_document(document):
    # è‡ªåŠ¨é‡è¯•ï¼ŒæŒ‡æ•°é€€é¿
    result = await analyze(document)
    return result
```

#### æ£€æŸ¥ç‚¹å’Œå›æ»š
```python
from python-backend.agents.error_handling import checkpoint_manager

# ä¿å­˜æ£€æŸ¥ç‚¹
checkpoint_manager.save_checkpoint(
    workflow_id="workflow_123",
    stage="analysis",
    data={"result": analysis_result}
)

# å›æ»šåˆ°æ£€æŸ¥ç‚¹
recovered_data = checkpoint_manager.rollback_to_checkpoint(
    workflow_id="workflow_123",
    stage="analysis"
)
```

#### é”™è¯¯æ¢å¤
```python
from python-backend.agents.error_handling import error_recovery_manager

# è®°å½•é”™è¯¯
error_recovery_manager.record_error(
    workflow_id="workflow_123",
    stage="content_generation",
    error=exception,
    context={"attempt": 1}
)

# æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
if error_recovery_manager.should_retry("workflow_123", "content_generation"):
    # å°è¯•æ¢å¤
    result = await error_recovery_manager.recover_from_error(
        workflow_id="workflow_123",
        stage="content_generation",
        recovery_func=regenerate_content
    )
```

### 3. è´¨é‡æ§åˆ¶

#### å†…å®¹è´¨é‡æ£€æŸ¥
```python
from python-backend.agents.quality_control import content_quality_checker

# ç»¼åˆè´¨é‡æ£€æŸ¥
results = content_quality_checker.comprehensive_check(
    content={
        "technical": "æŠ€æœ¯æ–¹æ¡ˆå†…å®¹...",
        "commercial": "å•†åŠ¡æ–¹æ¡ˆå†…å®¹...",
        "implementation": "å®æ–½è®¡åˆ’å†…å®¹..."
    },
    required_sections=["technical", "commercial", "implementation"]
)

if results["overall_passed"]:
    print("âœ… è´¨é‡æ£€æŸ¥é€šè¿‡")
else:
    print(f"âŒ å‘ç°é—®é¢˜: {results['issues']}")
    print(f"âš ï¸ è­¦å‘Š: {results['warnings']}")
```

#### è´¨é‡è¯„åˆ†
```python
from python-backend.agents.quality_control import QualityScorer

# è®¡ç®—è´¨é‡åˆ†æ•°
score = QualityScorer.calculate_quality_score(content, quality_checks)
level = QualityScorer.get_quality_level(score)

print(f"è´¨é‡åˆ†æ•°: {score:.2f}")
print(f"è´¨é‡ç­‰çº§: {level}")
# excellent, good, acceptable, needs_improvement, poor
```

#### ç”Ÿæˆä¼˜åŒ–å»ºè®®
```python
from python-backend.agents.quality_control import quality_optimizer

# ç”Ÿæˆæ”¹è¿›å»ºè®®
suggestions = quality_optimizer.generate_optimization_suggestions(quality_checks)

for suggestion in suggestions:
    print(f"ğŸ’¡ {suggestion}")
```

### 4. æ€§èƒ½ç›‘æ§

#### è®°å½•æŒ‡æ ‡
```python
from python-backend.agents.monitoring import performance_monitor

# è®°å½•æ“ä½œ
operation_id = "op_123"
performance_monitor.start_operation(operation_id)

# ... æ‰§è¡Œæ“ä½œ ...

performance_monitor.end_operation(
    operation_id,
    "collaborative_workflow",
    success=True
)

# è®°å½•LLMè°ƒç”¨
performance_monitor.record_llm_call(
    agent_name="content_generator",
    duration=2.5,
    success=True,
    token_count=1500
)

# è®°å½•å†…å®¹è´¨é‡
performance_monitor.record_content_quality(
    content_type="technical_proposal",
    quality_score=0.85
)
```

#### è·å–æ€§èƒ½æ‘˜è¦
```python
summary = performance_monitor.get_performance_summary()

print(f"LLMè°ƒç”¨æ€»æ•°: {summary['llm_calls']['total']}")
print(f"LLMæˆåŠŸç‡: {summary['llm_calls']['success_rate']:.2%}")
print(f"å¹³å‡å“åº”æ—¶é—´: {summary['llm_calls']['avg_duration']:.2f}s")
print(f"å·¥ä½œæµæˆåŠŸç‡: {summary['workflows']['success_rate']:.2%}")
print(f"å¹³å‡å†…å®¹è´¨é‡: {summary['content_quality']['avg_score']:.2f}")
```

#### é…ç½®å‘Šè­¦
```python
from python-backend.agents.monitoring import alert_manager

# æ·»åŠ è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™
alert_manager.add_alert_rule(
    rule_name="high_failure_rate",
    metric_name="llm_call_duration",
    condition="lt",
    threshold=0.7,  # æˆåŠŸç‡ä½äº70%
    severity="critical"
)

# æ£€æŸ¥å‘Šè­¦
alert_manager.check_alerts()

# è·å–æ´»è·ƒå‘Šè­¦
active_alerts = alert_manager.get_active_alerts()
for alert in active_alerts:
    print(f"ğŸš¨ {alert['severity']}: {alert['rule_name']}")
    print(f"   å½“å‰å€¼: {alert['current_value']}")
    print(f"   é˜ˆå€¼: {alert['threshold']}")
```

### 5. æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨ç¼“å­˜
```python
from python-backend.agents.performance_optimization import with_cache, cache_manager

# ç¼“å­˜è£…é¥°å™¨
@with_cache(cache_manager, ttl=3600, key_prefix="analysis_")
async def expensive_analysis(document):
    # ç»“æœä¼šè¢«ç¼“å­˜1å°æ—¶
    result = await analyze_document(document)
    return result

# æ‰‹åŠ¨ç¼“å­˜æ“ä½œ
cache_manager.set("key", value, ttl=1800)
cached_value = cache_manager.get("key")
cache_manager.delete("key")

# æ¸…ç†è¿‡æœŸç¼“å­˜
cache_manager.cleanup_expired()

# è·å–ç¼“å­˜ç»Ÿè®¡
stats = cache_manager.get_stats()
print(f"ç¼“å­˜æ¡ç›®æ•°: {stats['total_entries']}")
print(f"ç¼“å­˜å¤§å°: {stats['total_size_mb']:.2f} MB")
```

#### å¹¶è¡Œå¤„ç†
```python
from python-backend.agents.performance_optimization import parallel_executor

# å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
tasks = [process_item(item) for item in items]
results = await parallel_executor.execute_parallel(
    tasks,
    max_concurrent=5  # é™åˆ¶å¹¶å‘æ•°
)

# æ‰¹é‡å¤„ç†
results = await parallel_executor.execute_batch(
    items=large_item_list,
    process_func=process_single_item,
    batch_size=10,
    max_concurrent=3
)
```

#### èµ„æºä¼˜åŒ–
```python
from python-backend.agents.performance_optimization import resource_optimizer

# ä¼˜åŒ–æç¤ºè¯é•¿åº¦
long_prompt = "..." * 1000
optimized_prompt = resource_optimizer.optimize_prompt_length(
    long_prompt,
    max_length=4000,
    preserve_sections=["æ ¸å¿ƒéœ€æ±‚", "æŠ€æœ¯è¦æ±‚"]
)

# ä¼°ç®—Tokenæ•°é‡
text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬..."
token_count = resource_optimizer.estimate_token_count(text)
print(f"é¢„ä¼°Tokenæ•°: {token_count}")

# æˆæœ¬ä¼˜åŒ–
result = resource_optimizer.optimize_for_cost(
    prompt=long_prompt,
    max_tokens=2000,
    target_cost_reduction=0.3  # ç›®æ ‡é™ä½30%æˆæœ¬
)
print(f"åŸå§‹Token: {result['original_tokens']}")
print(f"ä¼˜åŒ–åToken: {result['optimized_tokens']}")
print(f"æˆæœ¬é™ä½: {result['cost_reduction']:.1%}")
```

### 6. äººå·¥å¹²é¢„

#### æ·»åŠ å¹²é¢„ç‚¹
```python
from python-backend.agents.agent_manager import AgentWorkflowManager

manager = AgentWorkflowManager()

# æ·»åŠ äººå·¥å¹²é¢„ç‚¹
intervention_id = manager.add_human_intervention(
    workflow_id="workflow_123",
    stage="content_generation",
    content={"draft": "åˆç¨¿å†…å®¹..."},
    reason="éœ€è¦äººå·¥å®¡æ ¸æŠ€æœ¯æ–¹æ¡ˆ"
)

# è·å–å¾…å¤„ç†çš„å¹²é¢„
pending = manager.get_pending_interventions()
for intervention in pending:
    print(f"å¹²é¢„ID: {intervention['id']}")
    print(f"é˜¶æ®µ: {intervention['stage']}")
    print(f"åŸå› : {intervention['reason']}")

# æäº¤åé¦ˆ
manager.submit_intervention_feedback(
    intervention_id=intervention_id,
    feedback={
        "approved": True,
        "comments": "æŠ€æœ¯æ–¹æ¡ˆåˆç†ï¼Œå»ºè®®å¢åŠ æ€§èƒ½æŒ‡æ ‡",
        "modifications": {"add_performance_metrics": True}
    }
)
```

---

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå®Œæ•´çš„æŠ•æ ‡æ–‡æ¡£ç”Ÿæˆæµç¨‹

```python
import asyncio
from python-backend.agents.agent_manager import AgentWorkflowManager

async def generate_bid_document():
    # é…ç½®
    config = {
        "model": "gpt-4",
        "temperature": 0.7,
        "max_tokens": 3000,
        "fastgpt_url": "http://localhost:3001"
    }
    
    # æ‹›æ ‡æ–‡æ¡£
    tender_document = """
    é¡¹ç›®åç§°ï¼šæ™ºæ…§åŸå¸‚ç®¡ç†å¹³å°å»ºè®¾é¡¹ç›®
    é¢„ç®—ï¼š500ä¸‡å…ƒ
    å·¥æœŸï¼š6ä¸ªæœˆ
    
    æŠ€æœ¯è¦æ±‚ï¼š
    1. é‡‡ç”¨å¾®æœåŠ¡æ¶æ„
    2. æ”¯æŒ10ä¸‡å¹¶å‘ç”¨æˆ·
    3. æ•°æ®å®‰å…¨ç­‰çº§ï¼šä¸‰çº§
    4. æä¾›ç§»åŠ¨ç«¯APP
    
    å•†åŠ¡è¦æ±‚ï¼š
    1. æä¾›3å¹´è´¨ä¿
    2. åˆ†æœŸä»˜æ¬¾
    3. æä¾›åŸ¹è®­æœåŠ¡
    """
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = AgentWorkflowManager()
    
    # å¯åŠ¨åä½œå·¥ä½œæµ
    print("ğŸš€ å¯åŠ¨åä½œå·¥ä½œæµ...")
    workflow_id = await manager.start_collaborative_workflow(
        tenant_id="company_001",
        tender_document=tender_document,
        config=config,
        max_iterations=3
    )
    
    # ç›‘æ§è¿›åº¦
    while True:
        status = manager.get_collaborative_workflow_status(workflow_id)
        
        print(f"ğŸ“Š çŠ¶æ€: {status['status']}")
        print(f"ğŸ“ é˜¶æ®µ: {status['current_step']}")
        print(f"â±ï¸  è¿›åº¦: {status['progress']:.1f}%")
        
        if status['status'] in ['completed', 'failed']:
            break
        
        await asyncio.sleep(5)
    
    # è·å–ç»“æœ
    if status['status'] == 'completed':
        result = status['result']
        
        print("\nâœ… å·¥ä½œæµå®Œæˆ!")
        print(f"ğŸ“ ä¼˜åŒ–è½®æ•°: {result['content']['iterations']}")
        print(f"â­ å®¡æ‰¹çŠ¶æ€: {result['verification']['approval_status']}")
        
        # ä¿å­˜ç»“æœ
        with open("bid_document.json", "w", encoding="utf-8") as f:
            import json
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° bid_document.json")
    else:
        print(f"\nâŒ å·¥ä½œæµå¤±è´¥: {status.get('error')}")

# è¿è¡Œ
asyncio.run(generate_bid_document())
```

### ç¤ºä¾‹2ï¼šå¸¦é”™è¯¯å¤„ç†çš„å†…å®¹ç”Ÿæˆ

```python
from python-backend.agents.content_generation_agent import ContentGenerationAgent
from python-backend.agents.error_handling import with_retry, RetryConfig, checkpoint_manager

async def generate_content_with_error_handling():
    # é…ç½®é‡è¯•
    retry_config = RetryConfig(
        max_retries=3,
        initial_delay=1.0,
        exponential_base=2.0
    )
    
    @with_retry(retry_config=retry_config)
    async def generate_with_retry(agent, requirements, knowledge):
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_manager.save_checkpoint(
            "workflow_001",
            "before_generation",
            {"requirements": requirements}
        )
        
        try:
            # ç”Ÿæˆå†…å®¹
            result = await agent.generate_technical_proposal(
                requirements,
                knowledge
            )
            
            # ä¿å­˜æˆåŠŸæ£€æŸ¥ç‚¹
            checkpoint_manager.save_checkpoint(
                "workflow_001",
                "after_generation",
                {"result": result}
            )
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤: {e}")
            # å›æ»šåˆ°ä¹‹å‰çš„æ£€æŸ¥ç‚¹
            checkpoint_data = checkpoint_manager.rollback_to_checkpoint(
                "workflow_001",
                "before_generation"
            )
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = ContentGenerationAgent("tenant_001", config)
    
    # æ‰§è¡Œç”Ÿæˆ
    result = await generate_with_retry(
        agent,
        requirements={"technical": ["å¾®æœåŠ¡æ¶æ„", "é«˜å¹¶å‘"]},
        knowledge={"best_practices": "..."}
    )
    
    print("âœ… å†…å®¹ç”ŸæˆæˆåŠŸ")
    return result
```

### ç¤ºä¾‹3ï¼šè´¨é‡æ§åˆ¶å’Œä¼˜åŒ–

```python
from python-backend.agents.quality_control import (
    content_quality_checker,
    QualityScorer,
    quality_optimizer
)

async def quality_control_workflow(content):
    # 1. ç»¼åˆè´¨é‡æ£€æŸ¥
    print("ğŸ” æ‰§è¡Œè´¨é‡æ£€æŸ¥...")
    quality_checks = content_quality_checker.comprehensive_check(
        content,
        required_sections=["technical", "commercial", "implementation"]
    )
    
    # 2. è®¡ç®—è´¨é‡åˆ†æ•°
    score = QualityScorer.calculate_quality_score(content, quality_checks)
    level = QualityScorer.get_quality_level(score)
    
    print(f"â­ è´¨é‡åˆ†æ•°: {score:.2f}")
    print(f"ğŸ“Š è´¨é‡ç­‰çº§: {level}")
    
    # 3. æ£€æŸ¥æ˜¯å¦é€šè¿‡
    if quality_checks["overall_passed"] and score >= 0.8:
        print("âœ… è´¨é‡æ£€æŸ¥é€šè¿‡")
        return content
    
    # 4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
    print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
    suggestions = quality_optimizer.generate_optimization_suggestions(quality_checks)
    
    for i, suggestion in enumerate(suggestions, 1):
        print(f"   {i}. {suggestion}")
    
    # 5. åº”ç”¨ä¼˜åŒ–ï¼ˆè¿™é‡Œéœ€è¦è°ƒç”¨LLMé‡æ–°ç”Ÿæˆï¼‰
    print("\nğŸ”„ åº”ç”¨ä¼˜åŒ–å»ºè®®...")
    # optimized_content = await apply_optimizations(content, suggestions)
    
    return content
```

---

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡
```bash
# .env
OPENAI_API_KEY=your_api_key
FASTGPT_URL=http://localhost:3001
CACHE_ENABLED=true
CACHE_TTL=3600
MAX_RETRIES=3
MAX_CONCURRENT=5
```

### é…ç½®æ–‡ä»¶
```python
# config/agent_config.py
AGENT_CONFIG = {
    # LLMé…ç½®
    "model": "gpt-4",
    "temperature": 0.7,
    "max_tokens": 3000,
    
    # çŸ¥è¯†åº“é…ç½®
    "fastgpt_url": "http://localhost:3001",
    "fastgpt_timeout": 30.0,
    
    # ç¼“å­˜é…ç½®
    "cache_enabled": True,
    "cache_ttl": 3600,  # 1å°æ—¶
    
    # é‡è¯•é…ç½®
    "max_retries": 3,
    "initial_delay": 1.0,
    "max_delay": 60.0,
    
    # å¹¶å‘é…ç½®
    "max_concurrent": 5,
    "batch_size": 10,
    
    # è´¨é‡æ§åˆ¶
    "quality_threshold": 0.7,
    "coverage_threshold": 0.8,
    "max_iterations": 3,
    
    # ç›‘æ§é…ç½®
    "monitoring_enabled": True,
    "alert_enabled": True
}
```

---

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
- âœ… å§‹ç»ˆä½¿ç”¨é‡è¯•è£…é¥°å™¨å¤„ç†ä¸ç¨³å®šçš„æ“ä½œ
- âœ… åœ¨å…³é”®é˜¶æ®µä¿å­˜æ£€æŸ¥ç‚¹
- âœ… è®°å½•é”™è¯¯å†å²ä»¥ä¾¿åˆ†æ
- âœ… å®ç°é™çº§ç­–ç•¥

### 2. æ€§èƒ½ä¼˜åŒ–
- âœ… å¯¹é‡å¤æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜
- âœ… å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡
- âœ… ä¼˜åŒ–æç¤ºè¯é•¿åº¦ä»¥é™ä½æˆæœ¬
- âœ… å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜

### 3. è´¨é‡æ§åˆ¶
- âœ… åœ¨å†…å®¹ç”Ÿæˆåç«‹å³è¿›è¡Œè´¨é‡æ£€æŸ¥
- âœ… è®¾ç½®åˆç†çš„è´¨é‡é˜ˆå€¼
- âœ… å®æ–½å¤šè½®ä¼˜åŒ–æœºåˆ¶
- âœ… ä¿ç•™äººå·¥å®¡æ ¸å…³é”®èŠ‚ç‚¹

### 4. ç›‘æ§å’Œå‘Šè­¦
- âœ… è®°å½•æ‰€æœ‰å…³é”®æ“ä½œçš„æŒ‡æ ‡
- âœ… è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼
- âœ… å®šæœŸæ£€æŸ¥æ€§èƒ½æ‘˜è¦
- âœ… åˆ†æå‘Šè­¦å†å²ä»¥ä¼˜åŒ–ç³»ç»Ÿ

### 5. èµ„æºç®¡ç†
- âœ… é™åˆ¶å¹¶å‘æ•°ä»¥é¿å…è¿‡è½½
- âœ… ä½¿ç”¨æ‰¹é‡å¤„ç†å¤§é‡æ•°æ®
- âœ… å®šæœŸæ¸…ç†æ—§æ•°æ®
- âœ… ç›‘æ§å†…å­˜ä½¿ç”¨

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šLLMè°ƒç”¨å¤±è´¥
**ç—‡çŠ¶**: é¢‘ç¹å‡ºç°LLMè°ƒç”¨è¶…æ—¶æˆ–å¤±è´¥

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. æŸ¥çœ‹é‡è¯•é…ç½®æ˜¯å¦åˆç†
4. æ£€æŸ¥æç¤ºè¯é•¿åº¦æ˜¯å¦è¿‡é•¿

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¢åŠ é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿ
retry_config = RetryConfig(
    max_retries=5,
    initial_delay=2.0,
    max_delay=120.0
)

# ä¼˜åŒ–æç¤ºè¯é•¿åº¦
optimized_prompt = resource_optimizer.optimize_prompt_length(
    prompt,
    max_length=3000
)
```

### é—®é¢˜2ï¼šå†…å®¹è´¨é‡ä¸è¾¾æ ‡
**ç—‡çŠ¶**: ç”Ÿæˆçš„å†…å®¹è´¨é‡åˆ†æ•°æŒç»­ä½äºé˜ˆå€¼

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥æç¤ºè¯è´¨é‡
2. æŸ¥çœ‹è´¨é‡æ£€æŸ¥çš„å…·ä½“é—®é¢˜
3. æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦æœ‰ç›¸å…³ä¿¡æ¯
4. æŸ¥çœ‹ä¼˜åŒ–å»ºè®®æ˜¯å¦è¢«æ­£ç¡®åº”ç”¨

**è§£å†³æ–¹æ¡ˆ**:
```python
# é™ä½è´¨é‡é˜ˆå€¼æˆ–å¢åŠ ä¼˜åŒ–è½®æ•°
workflow = CollaborativeWorkflow(tenant_id, config)
result = await workflow.execute_collaborative_workflow(
    tender_document,
    max_iterations=5  # å¢åŠ åˆ°5è½®
)

# æ£€æŸ¥å…·ä½“é—®é¢˜
quality_checks = content_quality_checker.comprehensive_check(content)
print(f"é—®é¢˜: {quality_checks['issues']}")
print(f"è­¦å‘Š: {quality_checks['warnings']}")
```

### é—®é¢˜3ï¼šæ€§èƒ½ç¼“æ…¢
**ç—‡çŠ¶**: å·¥ä½œæµæ‰§è¡Œæ—¶é—´è¿‡é•¿

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥æ˜¯å¦å¯ç”¨ç¼“å­˜
2. æŸ¥çœ‹æ˜¯å¦æœ‰å¹¶è¡Œå¤„ç†æœºä¼š
3. æ£€æŸ¥LLMè°ƒç”¨æ˜¯å¦è¿‡å¤š
4. æŸ¥çœ‹æ€§èƒ½ç›‘æ§æ•°æ®

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¯ç”¨ç¼“å­˜
cache_manager.set("analysis_result", result, ttl=3600)

# å¹¶è¡Œå¤„ç†
tasks = [task1, task2, task3]
results = await parallel_executor.execute_parallel(tasks, max_concurrent=3)

# æŸ¥çœ‹æ€§èƒ½æ•°æ®
summary = performance_monitor.get_performance_summary()
print(f"å¹³å‡å“åº”æ—¶é—´: {summary['llm_calls']['avg_duration']:.2f}s")
```

### é—®é¢˜4ï¼šå†…å­˜å ç”¨è¿‡é«˜
**ç—‡çŠ¶**: ç³»ç»Ÿå†…å­˜æŒç»­å¢é•¿

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ç¼“å­˜å¤§å°
2. æŸ¥çœ‹æ˜¯å¦æœ‰å†…å­˜æ³„æ¼
3. æ£€æŸ¥æ˜¯å¦æ¸…ç†æ—§æ•°æ®

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ¸…ç†è¿‡æœŸç¼“å­˜
cache_manager.cleanup_expired()

# å‹ç¼©å¤§æ•°æ®
from python-backend.agents.performance_optimization import memory_optimizer
compressed = memory_optimizer.compress_large_dict(large_data, max_value_length=1000)

# æ¸…ç†æ—§æ•°æ®
cleaned = memory_optimizer.cleanup_old_data(
    data_dict,
    max_age=timedelta(days=7)
)
```

---

## è”ç³»æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- ğŸ“– [å®Œæ•´æ–‡æ¡£](./IMPLEMENTATION_COMPLETE_FINAL.md)
- ğŸ› [é—®é¢˜è¿½è¸ª](./issues)
- ğŸ’¬ [è®¨è®ºåŒº](./discussions)

---

**æœ€åæ›´æ–°**: 2024-11-10  
**ç‰ˆæœ¬**: 1.0.0
